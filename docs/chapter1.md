---
hide:
  - toc
---

# Chapter 1: How a Neural Network Sees an Image

> â€œ*Before the model learns, it sees. Before it classifies, it computes. And what it seesâ€”starts with pixels, channels, and shapes.*â€

---

## Why This Chapter Matters

Every computer vision journey begins with an image. But hereâ€™s the twist: your neural network doesnâ€™t see an image the way you do. It sees numbers. And not just any numbersâ€”tensors of pixel values, reshaped and normalized to fit the modelâ€™s expectations.

If youâ€™ve ever run into errors like:

- â€œExpected 3 channels, got 1â€

- â€œShape mismatch: [1, 224, 224, 3] vs [3, 224, 224]â€

- â€œModel output is garbage despite clean codeâ€

â€¦then it probably started here: the image-to-tensor pipeline wasnâ€™t correctly handled.

In this chapter, weâ€™ll unpack the complete transformation from a JPEG or PNG file on disk to a model-ready tensor in memory. Weâ€™ll go step by stepâ€”from pixel arrays â†’ float tensors â†’ properly shaped inputsâ€”and explain how frameworks like PyTorch and TensorFlow treat the process differently.

Youâ€™ll see what the model sees. And that understanding will anchor everything you build later.

---

## Conceptual Breakdown

**ğŸ”¹ What Is an Image in Memory?**

To a neural network, an image is just a 3D arrayâ€”Height, Width, and Color Channels (usually RGB). For grayscale, itâ€™s just HÃ—W. For RGB, itâ€™s HÃ—WÃ—3.

But raw image files (JPEG, PNG) are compressed formats. To use them in training, we:

1. **Load** the image into memory

2. **Convert** it to an array of pixel values (0â€“255)

3. **Normalize/scale** those values (e.g., 0.0 to 1.0 or with mean/std)

4. **Reshape** it into a tensor format the model expects

Each step matters. A mismatch in any of these can wreck your model.

---

**ğŸ”¹ Tensor Layouts: [H, W, C] vs [C, H, W]**

Different frameworks use different conventions:

- TensorFlow uses `[Height, Width, Channels]`

- PyTorch uses `[Channels, Height, Width]`

The reason? Internal memory layout optimizations. But for you, it means that converting between these shapes is crucial when preparing images for your models.

---

**ğŸ”¹ Model Input Shape: Why It Matters**

Neural networks are strict about input shape:

- ResNet, MobileNet, EfficientNet, etc. expect a specific input size and layout

- Channels must match: grayscale (1), RGB (3), etc.

- Batch dimension must exist: `[1, C, H, W]` or `[1, H, W, C]`

Even for a single image, you **must simulate a batch**â€”most models donâ€™t accept raw 3D tensors.

---

**ğŸ”¹ Visual Walkthrough: Image â†’ Tensor â†’ Model**

Letâ€™s break down what happens:
```css
Image File (e.g., 'dog.png')
      â†“
Load into memory (PIL / tf.io / OpenCV)
      â†“
Convert to NumPy or Tensor (shape: HÃ—WÃ—3)
      â†“
Normalize (e.g., /255.0 or mean/std)
      â†“
Transpose (if using PyTorch: â†’ CÃ—HÃ—W)
      â†“
Add batch dim (â†’ 1Ã—CÃ—HÃ—W or 1Ã—HÃ—WÃ—C)
      â†“
Feed to CNN
```

---

## PyTorch Implementation

Hereâ€™s how you go from image file to model-ready tensor in PyTorch:
```python
from PIL import Image
import torchvision.transforms as T

# 1. Load image
image = Image.open("dog.png").convert("RGB")

# 2. Define transform pipeline
transform = T.Compose([
    T.Resize((224, 224)),
    T.ToTensor(),  # Converts to [0,1] and switches to [C, H, W]
    T.Normalize(mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225])  # Pretrained model mean/std
])

# 3. Apply transforms
tensor = transform(image)  # shape: [3, 224, 224]

# 4. Add batch dimension
input_tensor = tensor.unsqueeze(0)  # shape: [1, 3, 224, 224]
```

---

## TensorFlow Implementation

The same pipeline in TensorFlow looks like this:
```python
import tensorflow as tf

# 1. Load image
image = tf.io.read_file("dog.png")
image = tf.image.decode_png(image, channels=3)

# 2. Resize and convert to float32
image = tf.image.resize(image, [224, 224])
image = tf.cast(image, tf.float32) / 255.0

# 3. Normalize
mean = tf.constant([0.485, 0.456, 0.406])
std = tf.constant([0.229, 0.224, 0.225])
image = (image - mean) / std

# 4. Add batch dimension
input_tensor = tf.expand_dims(image, axis=0)  # shape: [1, 224, 224, 3]
```

---

# Framework Comparison Table
|Step	            |PyTorch	                        |TensorFlow                             |
|-------------------|-----------------------------------|---------------------------------------|
|Load image	        |`PIL.Image.open()`	                |`tf.io.read_file() + tf.image.decode`  |
|Resize	            |`T.Resize((H, W))`	                |`tf.image.resize()`                    |
|Convert to float	|`T.ToTensor()` (scales to 0â€“1)	    |`tf.cast(..., tf.float32) / 255.0`     |
|Normalize	        |`T.Normalize(mean, std)`	        |Manual: `(image - mean) / std`         |
|Layout	            |`[C, H, W]`	                    |`[H, W, C]`                            |
|Add batch dim	    |`.unsqueeze(0)`	                |`tf.expand_dims(..., axis=0)`          |

---

## Mini-Exercise

Choose any image file and:

1. Load and visualize the original

2. Convert it to a tensor using both PyTorch and TensorFlow

3. Apply normalization

4. Print shape at each step

5. Confirm final shape matches model input requirement

**Bonus**: Try visualizing the image after normalization. What do the pixel values look like now?

---




